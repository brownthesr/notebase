# 2: Normed Vector Spaced and Banach Spaces

## 2.1

### Definition: Vector space

 A vector space over a field $\mathbb{K}$ is a set of elements $X\neq \empty$ (called vectors) with two operations

- Addition: $X\times X\rightarrow X$
- Multiplication $X\times K \rightarrow X$

Which satisfies a bunch of different properties.

The usual Fields that we take are $K=\R, \mathbb{C}$

#### Examples

$$\begin{align}
\R^n, \mathbb{C}^n, C[a,b]
\end{align}$$

What about $l^p$? This is also a vector space just by defining things component wise.

We mainly just need to show that $x+y\in l^p$ if $x,y\in l^p$
$$\begin{align}
||x+y||_{l^2}\leq ||x||+||y||
\end{align}$$

### Definition: Subspace
A subspace $Y\subset X$ is called a subspace if $\alpha x+\beta y\in Y$. Basically Y is closed under vector addition and multiplication by scalar.

#### Note
$$\begin{align}
\{0\},X \text{ Are always subspaces of }X
\end{align}$$

### Definition: Linear Combinations
A linear combination of $x_1,\dots, x_m\in X$ is of the form:
$$\begin{align}
\alpha_1x_1+\dots+\alpha_mx_m
\end{align}$$

### Definition: Span
Let $M\subset X$, The set of all *finite* linear combination of elements in M is span $M$.

### Definition: Linear Dependence and independence
$M=\{x_1,\dots, x_r\}\subset X$
M is linearly independent if
$$\begin{align}
\alpha_1x_1+\dots \alpha_rx_r=0\iff \alpha_1=\dots=\alpha_r=0
\end{align}$$
M is linearly dependent if :
$$\begin{align}
\exists \alpha_i\\
\alpha_1x_1\dots \alpha_rx_r=0
\end{align}$$
Where the coefficients are not all zero.

### Definition: Finite Dimensional Vector space.
A vector space x is finite dimensional if it is spanned by a finite combination of vectors.

The dimension of a finite dimensional vector space $X$ is the cardinality of the smallest set spanning all of $X$.

#### Consequence:
If $dim(X)=n$ then $\exists \{x_1,\dots,x_n\}$ where the span is the whole space.

Any set of vectors with $n+1$ vectors are linearly dependent

#### Examples:
$$\begin{align}
C[a,b],l^p \text{ are infinite dimensional }\\
\R^n \text{ is finite dimensional}
\end{align}$$
any $x\in X$ has a unique linear combination of basis vectors. For example in $\R^n$ we can just take the canonical basis.

### Definition: (Hamel) Basis (NOT INFINITE!)
This is any Linearly independent $B\subset X$ where the span $B=X$

Note $B$ is not necessarily finite.

any $x\in X$ can be expressed as a *finite* linear combination of elements of B.

#### Note
- Every finite dimensional Vector space has a basis (this is clear)
- Every infinite dimensional Vector space has a basis (zorns lemma)
- Every Hamel basis of $X$ has the same cardinality.
- Every proper subspace $S\subsetneq X$ where $X$ is finite dimensional then dim $S<$ dim $X$

## 2.2 Normed Vector Spaces and Banach Spaces.

### Definition: Norm
- $||x||\geq 0$, $||x||=0\iff x=0$
- $||ax||=|a|||x||$
- Triangle inequality

Consequences:
- we can show that the reverse triangle inequality holds.
- $||x||$ is a continuous function $X\rightarrow \R$
- A norm defines a metric.
- Not every metric comes from a norm
    - Points on a sphere
    - The $\frac{|x-y|}{1+|x-y|}$ is a metric but $\frac{|x|}{1+|x|}$ is not a norm.

### Definition: Banach Space
A Complete normed vector space is a Banach Space.

by same construction as for metric spaces any normed vector space has a unique completion $\hat X$ up to isometry

#### Examples:
- $\R^n, \mathbb{C}^n$ are complete metric spaces (with usual norm).
- $l^p$ are also complete metric spaces $||x||_p=(\sum\limits_{k=1}^{\infty}\left(|x_i|^p\right))^\frac{1}{p}$ for $1\leq p< \infty$
- $l^\infty$
- Continuous functions with sup norm
- Continuous functions with $L^2$ norm are not complete.
    - The completion of this is $L^2$

<!-- TODO: What are good books to read on more advanced functional analysis not 6210 -->

## 2.3: More properties of Normed Vector Spaces
A Subspace $Y$ of a banach space $X$ is complete iff $Y$ is closed in $X$.

### Definition: Convergent Sequence
A sequence $x_n$ in a normed vector space is convergent if $\exists x\in X$ with $\lim_{n \rightarrow \infty}||x_n-x||$

### Definition: Cauchy Sequence
The usual definition

### Definition: Convergence of Series
What do we mean by an infinite series of vectors

We start with partial sums:
$$\begin{align}
s_n = x_1+\dots + x_n=\sum\limits_{k=1}^{n}\left(x_k\right)
\end{align}$$
if these have a limit then we say that the series converges.

### Definition: Absolute convergent
$$\begin{align}
\sum\limits_{k=1}^{\infty}\left(x_k\right)
\end{align}$$

is absolutely convergent if

$$\begin{align}
\sum\limits_{k=1}^{\infty}\left(||x_k||\right)
\end{align}$$
converges as a series in $\mathbb{R}$

Note that X is complete iff (absolute convergence implies convergence). This is a characterization of completeness.

### Definition: Schauder basis
If a normed vector space contains a sequences $e_n$ such that you can write any vector as a unique infinite series. Then this sequence is called a schauder basis.

#### Example:
$$\begin{align}
e_1=(1,0,\dots)\\
e_2=(0,1,0\dots)\\
\vdots
\end{align}$$
for $l^p$

Fact if $X$ has a schauder basis then $X$ is separable.

However if $X$ is separable then it does not mean that it has a schauder basis.

## 2.4: Finite dimensional normed vector spaces
### Lemma: Bounding linear combinations
Let $\{x_1,\dots,x_n\}$ be n linearly independent vectors in $X$. Then $\exists c > 0$ with
$$\begin{align}
||\alpha_1x_1+\dots+\alpha_nx_n||\geq c(|\alpha_1|+\dots+|\alpha_n|)
\end{align}$$
Proof:

$s=|\alpha_1|+\dots+|\alpha_n|$ Note that if $s=0$ then this holds trivially since that implies $|\alpha_i|=0$.

if $s\neq 0$ then we will divide by s on both sides:
$$\begin{align}
||\beta_1x_1+\dots+\beta_1x_n||\geq c
\end{align}$$

We then know that $\sum |\beta_k|=1$

So we just need to show this easier inequality where they sum to one.

Assume BWOC that this inequality does not hold.

Then $\exists y_m$ where $y_m=\beta_1^mx_1+\dots +\beta_n^mx_n$ Where $\sum |\beta_i^m|=1$

Such that $y_m\rightarrow 0$

Since $\sum\limits_{k=1}^{n}\left(|\beta_i^m|\right)=1$ then we know that $|\beta_i^m|\leq 1$ for any $i\in {1,n}, \in \mathbb{Z}$

We can then invoke bolzano Weierstrauss which states that there is a convergent subsequence for each $\beta_j^m$ (for fixed j)

We first do this for $\beta_1^m$ call what this converges to $\beta_1$ this gives us a subsequence of the original sequence $y^1_m$.

We then know that $y^1_m$ has a subsequence where $\beta_2^m$ converges to something called $\beta_2$. call this new subsequence $y_m^2$.

Keep repeating this until the process terminates (since we are in finite dimensions). We are left with $y_m^n$ a subsequence of the original sequence.

This sequence converges to $y_m^n\rightarrow y=\sum \beta_k x_k=0$ which should be zero by our assumption on y. however $\sum |\beta_j|=1$. By linearly independence of $x_j$ that means that each $\beta_j$ is zero which is a contradiction.

So we cannot create a sequence that approaches zero.

### Theorem: Every Finite dimensional subspace of X is complete
<!-- TODO: The idea here is that we decompose any cauchy sequence in terms of the basis vectors. We then show that this gives us a cauchy sequence of coefficients. By completeness of $\R$ we can then identify a candidate limit for each coeff. Use this limit as the limit of the cauchy sequence. -->
### Theorem: Every finite dimensional subspace of X is closed
### Definition: Equivalence of norms
### Theorem: All norms on finite vector spaces are equivalent.
Proof:

Take a bunch of linearly independet vectors then:
$$\begin{align}
|a|||x_1||+\dots + |b|||x_n||\geq ||ax_1+\dots +bx_n||\geq C(|a|+\dots + |b|)
\end{align}$$
So we have sandwhich this in between two 1 norms

We can use the completeness of $\R^n$ and equivalence of norms to prove completeness of any finite dimensional vector space.
